* [ClamAV](#clamav)
   * [Quick Reference](#quick-reference)
      * [Container design/behavior](#container-designbehavior)
      * [Environment Variables](#environment-variables)
   * [Use Cases](#use-cases)
      * [Basic - All-in-one Container](#basic---all-in-one-container)
      * [Advanced uses](#advanced-uses)
         * [Two containers directly on the VPSA](#two-containers-directly-on-the-vpsa)
         * [Two containers directly on the VPSA, N containers outside the VPSA](#two-containers-directly-on-the-vpsa-n-containers-outside-the-vpsa)
         * [Customizing ClamAV/Freshclam configs, or storing AntiVirus Definitions on the log volume](#customizing-clamavfreshclam-configs-or-storing-antivirus-definitions-on-the-log-volume)
         * [Forcing the "next" manifest scan to be a "full" scan](#forcing-the-next-manifest-scan-to-be-a-full-scan)
         * [Debugging FIND_EXTRA](#debugging-find_extra)
   * [Design notes](#design-notes)
      * [LOG_PATH folder structure](#log_path-folder-structure)
      * [Preparing a proxy for updating virus definitions](#preparing-a-proxy-for-updating-virus-definitions)
      * [Considerations for multiple threads, containers, hosts for AV scanning](#considerations-for-multiple-threads-containers-hosts-for-av-scanning)
   * [Testing](#testing)
   * [Support](#support)

# ClamAV

ClamAV is a mature open source AntiVirus solution for Linux.  This container periodically walks the filesystem to monitor changes in file shares, then feed the list of files to the ClamAV service for virus scanning.  Infected files are sent to quarantine and events are logged.  

## Quick Reference
### Container design/behavior
This container wraps the official ClamAV software with our own scripts to make it more resliant to VPSA maintenance operations as well as some tuneables to reduce/increase/distribute it's resource requirements per user.  
There are essentially 2 core pieces to this container:
* find_modified.sh - Walks all filesystems provided by SCAN_PATH looking for objects moditifed since the previous scan, stores the resulting manifest files for later scanning
* avscan_queue.sh - Processes the resulting manifest files generated by the previous script using the ClamAV service

Decoupling the object detection from the antivirus scan operation enables the antivirus scan to be distributed and resumable. This also improves the rate of detection of objects on the target filesystem as neither script is explicitly waiting on one another.  
Both scripts are configured to run once per hour at a randomized minute offset.

### Environment Variables
| Variable | Is Required | Example/Options | Purpose |
|---|---|---|---|
| LOG_PATH | **required** | `/export/logs` | Stores clamd configuration files, all logs and the scan queue |
| QUAR_PATH | optional | `/export/infected` | If defined, ClamAV will move infected files here |
| SCAN_PATH | optional-on-VPSA<br />required-elsewhere | `/export/vol-a /export/vol-b` | Space-delimited list of volumes, if undefined on a VPSA, the volumes are auto-detected. Detection does not work if not run on a VPSA. |
|||||
| CLAM_MODE | optional | `both`<br>`find`<br>`av` | Default: `both`. Essentially disables one of the two behaviors outlined above. This is useful when separating or distributing the two workloads to leverage external resources. |
|||||
| FIND_CRON | optional | `*/15 * * * *` | Overrides the default once-per-hour configuration with a user-provided  |
| FIND_THREADS | optional | `2` | If many unique volumes are in use, this permits scanning them in parallel. Has no effect if only monitoring a single volume |
| FIND_EXTRA | optional | `! \( -name *.ignore -o -name *.DS_Store -o -name "thumbs.db" \)` | Additional arguments to pass to the Linux `find` command to tailor the results. This can be used to exclude or reduce the scope of the resulting manifest files to be scanned. More information on `find` is available [Here](https://manpages.ubuntu.com/manpages/focal/man1/find.1.html) |
| MANIFEST_LINES | optional | `1000` | Default: `1000`. Number of objects to be stored per manifest file. |
|||||
| SCAN_CRON | optional | `*/30 * * * *` | Overrides the default once-per-hour configuration with a user-provided  |
| SCAN_THREADS | optional | `4` | Default: `1`. The number of parallel threads sending files to the clamd service for scanning. Script processes 1 manifest at a time, but this many objects within that manifest in parallel. |
|||||
| DISABLE_FRESHCLAM | optional | `yes` | Default: undefined. Setting this to any value will disable freshclam from updating the local virus definitions. This is useful if running multiple `av` containers with a scared virus definitions folder. |
| DISABLE_DAILY_REPORT | optional | `yes` | Default: undefined. Disables running the daily report and/or notifying the user. |
|||||
| VPSA_ACCESSKEY | optional | `ZV4JE12C9F6955E5D4S9-001` | Required for daily notification of any detected infections. Leverages VPSA API to submit a support ticket with the last day's scan results. Reports are only generated if `CLAM_MODE` is undefined or set to `both` or `find`. |
| VPSA_IP | optional | `172.10.1.50` | Only necessary if running the container outside the VPSA and `find` behavior is enabled. VPSA IP is detected automatically if running on the VPSA directly. |
|||||
| PROXY_SERVER | optional | `192.168.99.100` | IP Address of an available squid proxy for `freshclam` to update local virus definitions. This is necessary if the VPSA's gateway is not providing a path to the internet, or if Public IP configurations are not available. |
| PROXY_PORT | optional | `3128` | Port of an available squid proxy for `freshclam` to update local virus definitions. |
|||||
| SSH_SERVICE | optional | `disabled` or `enabled` | Default: `disabled`. An SSHd service is available for debugging purposes. Default credentials are **root**/**zadara** |

## Use Cases
### Basic - All-in-one Container
This configuration will scan data1 and data2 volumes for changes in the previous hour, and will generate a support ticket once-per-day of any detected infections IF any infections are detected.  
Freshclam will use the VPSAs Frontend interface to try to update it's definitions twice a day, this may not work in some environments per network security policies.

Configure the container as follows:
* Volumes
  * clamav_log > /export/log
  * clamav_quar > /exprt/quar
  * data1 > /export/data1
  * data2 > /export/data2
* Environment Variables
  * LOG_PATH: /export/log
  * QUAR_PATH: /export/quar
  * VPSA_ACCESSKEY: XXXXXXXXXXXXXXXXXXXX-001


### Advanced uses
#### Two containers directly on the VPSA
This configuration is essentially the basic case but split into 2, this grants the user the ability to scan for file changes throughout the day, but only perform AV scans of the objects during specific timeframes by stopping/starting the secondary container.  
It is important that the volume mappings are identical on all containers, as this is recorded into the manifests for processing.
| Cfg | Find Container | AV Container |
|---|---|---|
| Volumes | clamav_log > /export/log<br>clamav_quar > /export/quar<br>data1 > /export/data1<br>data2 > /export/data2 | clamav_log > /export/log<br>clamav_quar > /export/quar<br>data1 > /export/data1<br>data2 > /export/data2 |
| Environment Variables | LOG_PATH: /export/log<br>QUAR_PATH: /export/quar<br>VPSA_ACCESSKEY: XXXXXXXXXXXXXXXXXXXX-001<br>CLAM_MODE: find | LOG_PATH: /export/log<br>QUAR_PATH: /export/quar<br>CLAM_MODE: av |

#### Two containers directly on the VPSA, N containers outside the VPSA
This is a further extension of the two-containers case, but also using an external host with the same volumes mapped via NFS. For this example, I've also increased the scan-threads-per-container to 2.  
This usecase offloads the scanning to an external host, but will also increase network traffic requirements, please keep this in mind.  
Follow the previous usecase to configure the two containers on the VPSA itself, then you can leverage the following docker-compose file:
```
version: '3'
services:
  clamav:
    image: zadara/clamav-cron:latest
    volumes:
    - clamav_log:/export/log
    - clamav_quar:/export/quar
    - data1:/export/data1
    - data2:/export/data2
    environment:
      LOG_PATH: "/export/log"
      QUAR_PATH: "/export/quar"
      SCAN_PATH: "/export/data1 /export/data2"
      CLAM_MODE: "av"
      SCAN_THREADS: "2"
volumes:
  clamav_log:
    driver_opts:
      type: "nfs"
      o: "addr=${VPSA_IP},nolock,soft,rw"
      device: ":/export/clamav_log"
  clamav_quar:
    driver_opts:
      type: "nfs"
      o: "addr=${VPSA_IP},nolock,soft,rw"
      device: ":/export/clamav_quar"
  data1:
    driver_opts:
      type: "nfs"
      o: "addr=${VPSA_IP},nolock,soft,rw"
      device: ":/export/data1"
  data2:
    driver_opts:
      type: "nfs"
      o: "addr=${VPSA_IP},nolock,soft,rw"
      device: ":/export/data2"
```

#### Customizing ClamAV/Freshclam configs, or storing AntiVirus Definitions on the log volume
On startup, the container will check for `clamd.conf` and `freshclam.conf` files in `${LOG_PATH}/conf`. These may be customized as required, and then simply restart the containers to have them take affect.  
For example, here is a procedure to enable storing the AV definitions on the log volume so that they can be updated manually.
* Start the container once to prepare the log volume, then stop it about 2 minutes later
* Create a "definitions" folder on the clamav_log or ${LOG_PATH} volume
* Inside the `conf/clamd.conf` file, replace `DatabaseDirectory /var/lib/clamav` with `DatabaseDirectory /export/log/definitions`
* Inside the `conf/freshclam.conf` file, replace `DatabaseDirectory /var/lib/clamav` with `DatabaseDirectory /export/log/definitions`
* Place all `.cvd` or `.dat` Virus Definitions files into the definitions directory
* Start any/all AV containers

#### Forcing the "next" manifest scan to be a "full" scan
Within the LOG_PATH is a folder "stats", which contains a number of csv files. Each one of these tracks the execution times of the `find` scrip, and are used to dictate the cutoff time for the next time the script runs.  
The naming convention of these files is the MD5sum of the SCAN_PATH(eg: /export/data1) name.
* Obtain the last line of the desired volume's csv in ${LOG_PATH}/stats/<hash>-find.csv
  * `# tail -n1 0e5eac26421ead27281548f9fa59992e-find.log` > `/export/data1,0e5eac26421ead27281548f9fa59992e,1646096282,1646096282,1,1000`
* Change columns 3 and 4 to `0` and append the file with the line
  * `# echo '/export/data1,0e5eac26421ead27281548f9fa59992e,0,0,1,1000' > 0e5eac26421ead27281548f9fa59992e-find.log`
* The next time the `find` script is executed by cron(hourly or per FIND_CRON variable), it will remove the timeframe restriction which will cause ALL files to be put into manifests for scanning

#### Debugging `FIND_EXTRA`
The `FIND_EXTRA` environment variable is intended for adding custom `find` arguments when finding files to be scanned. This can be used to ensure they never end up in a manifest, or add other complexities.  
The string is parsed [mostly] raw into an argument array and added to the existing find command.  
You can locate the "literal" `find` command being executed with in the ${LOG_PATH}/logs-cron/find_modified.*.log file for debugging purposes.  

The script will automatically inject:
* `-'type' 'f'` - Search for files
* `'-newermt' '2022-03-01 22:24:01+00:00'` - Modified time newer than the start of the last execution

Examples:
| FIND_EXTRA | Resulting "full" find command (Excluding newermt) | Outcome |
|---|---|---|
| `-executable` | `find '/export/data1' '-type' 'f' '-executable' '-print0' ` | Files with their executable bit set |
| `\( -size +100M \)` | `find '/export/data1' '-type' 'f' '(' '-size' '+100M' ')' '-print0' ` | Files greater than 100M |
| `! \( -name *.ignore \)` | `find '/export/data1' '-type' 'f' '!' '(' '-name' '*.ignore' ')' '-print0' ` | Ignore files with the extension .ignore|
| `! \( -name *.ignore -o -name *.ignore2 -o -name "a b" \)` | `find '/export/data1' '-type' 'f' '!' '(' '-name' '*.ignore' '-o' '-name' '*.ignore2' '-o' '-name' 'a b' ')' '-print0' ` | Ignore files with the extensions .ignore, .ignore2 or named 'a b' |
| `! \( -name *.ignore -o -name .DS_Store -o -name "thumbs.db" \)` |  `find '/export/data1' '-type' 'f' '!' '(' '-name' '*.ignore' '-o' '-name' '.DS_Store' '-o' '-name' 'thumbs.db' ')' '-print0' ` | Ignore files with the extension .ignore, or named .DS_Store or thumbs.db |
| `! \( -path */.git/* -o -path */node_modules/* -o -path "*/.idea/*" \)` |  `find '/export/data1' '-type' 'f' '!' '(' '-path' '*/.git/*' '-o' '-path' '*/node_modules/*' '-o' '-path' '*/.idea/*' ')' '-print0' ` | Ignore all files inside any .git, node_modules or .idea folders at any depth |

  
## Design notes
### LOG_PATH folder structure
| Folder | Contents | Purpose |
|---|---|---|
| conf | clamd.conf<br>freshclam.conf | Config files for the AV services are copied here if not found, then are copied back for use. |
| logs-cron | `find_modified.*.log`<br>`avscan_queue.*.log`<br>`freshclam_cron.*.log` | Output from the scripts run by cron within the containers. Uses the container's randomized "hostname" in the filename to avoid log collision. |
| logs-service | `clamd_svc.*.log` | Logs from the clamd system service itself, again using the container's "hostname" to avoid log collision. |
| queue | `*.manifest` | `\0`(`null`) delimited text files containing lists of files to be scanned. Is processed by avscan_queue scripts and deleted on completion. |
| scans | `YYYY\MM\YYYY-MM-DD.{log,infected,error}` | Logfile for each day containing the timestampl and scan results from `clamdscan`. Used by the daily report script to determine if any infections were detected in a 24 hour period. |
| stats | `*-find.csv`<br>`av_scan.YYY-MM.csv` | CSV files for each data volume being scanned by find_modified tracking execution timestamps, this is used to determine each scan's cutoff time.<br>av_scan files contain the quantity numbers from the daily reports |

### Preparing a proxy for updating virus definitions
Some private environments have their VPSAs configured with a functioning outbound internet gateway, not all do. So a backup option is to provide a squid proxy on a supplemental VM within the user network, which can be used by `freshclam` to update it's local antivirus definitions.  
Here are some quick steps for a "fresh" Ubuntu-based host:
```
sudo apt-get -y install squid3
```
Open the squid configuration file
```
vim /etc/squid3/squid.conf
```
Add this at the end of the acl part of the file around line 920 of conf file, you can tune this to be more secure as needed.
```

        # Start squid addition here, add your VPSA IP
        acl vpsa src <VPSA IP>/32

        acl outbound dstdom_regex .*

        #https_access allow vpsa outbound
        http_access allow vpsa outbound
```
Restart the Squid service
```
sudo systemctl restart squid3
```
Then add the following environment variables to the relevant docker container(VPSA-hosted or other):
* `PROXY_SERVER` - IP of the squid host
* `PROXY_PORT` - Port of the squid service, usually 3128 by default



### Considerations for multiple threads, containers, hosts for AV scanning
The decisions in code present here are intended to address a wide scope of usecases and environments while trying to avoid introducing significant impact to the user.  
* Multiple threads - Multiple threads within a single container allow leveraging a single active AV engine service to process files in a parallel fashion. When running on a VPSA with potentially cost-limited memory resources, this is the most efficient option.
* Multiple containers - For every "av" container running, the container will require somewhere around 1-2.5GB of RAM for the running `clamd` service. This is before considering the files being loaded into RAM for scanning. So running multiple AV containers on a VPSA is generally not an ideal configuration. However there this consideration is not as significant when running on an external compute environment.
* Multiple hosts - With this distributed design, standard compute hosts may be leveraged to assist in the scanning. This enables compute resource configurations outside that offered by the VPSA, however this also introduces an increase in the necessary network traffic as the file is accessed over NFS.

## Testing
You can use the EICAR Standard Anti-Virus Test File as described here: https://en.wikipedia.org/wiki/EICAR_test_file
or drop the following EICAR string in a test file.  
```
X5O!P%@AP[4\PZX54(P^)7CC)7}$EICAR-STANDARD-ANTIVIRUS-TEST-FILE!$H+H*
```
During an actual test, you should observe the EICAR file move from the scan directory to the quarantine directory along with log output indicating the test virus was discovered.

## Support
Please contact Zadara Support with any questions regarding this container.
